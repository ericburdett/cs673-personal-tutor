{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal-Tutor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYJnZgtw5RtUpl/A4pOLeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs673-personal-tutor/blob/master/Personal_Tutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPwFJK2Q3is",
        "colab_type": "text"
      },
      "source": [
        "# Personal Tutor\n",
        "\n",
        "This notebook contains code for the Personal Tutor System built for CS673: Computational Creativity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzpCKzikWxA3",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn2-Iv5RGY_9",
        "colab_type": "code",
        "outputId": "baac3772-b0df-474b-fd80-3cef971e2a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "!pip install gpt-2-simple\n",
        "!pip install gtts"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.17.5)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.8)\n",
            "Collecting gtts\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/0c/4ca77eca3b739a4a08360930643f58d714e302fee0d2f8c654e67d9af8e7/gTTS-2.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gtts) (1.12.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gtts) (4.6.3)\n",
            "Collecting gtts-token>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/25/ca6e9cd3275bfc3097fe6b06cc31db6d3dfaf32e032e0f73fead9c9a03ce/gTTS-token-1.1.3.tar.gz\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gtts) (7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gtts) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (1.24.3)\n",
            "Building wheels for collected packages: gtts-token\n",
            "  Building wheel for gtts-token (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gtts-token: filename=gTTS_token-1.1.3-cp36-none-any.whl size=4097 sha256=9562adeb78b23d828ed5a7866d6833bf56f0acc754e2ba826b6c74ac917fc81f\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/11/61/33f7e51bf545e910552b2255eead2a7cd8ef54064b46dceb34\n",
            "Successfully built gtts-token\n",
            "Installing collected packages: gtts-token, gtts\n",
            "Successfully installed gtts-2.1.1 gtts-token-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUN5YCJsWzAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import string\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import gpt_2_simple as gpt2\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from gtts import gTTS \n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from IPython.display import Audio, HTML\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iLmsxoZGjSB",
        "colab_type": "code",
        "outputId": "bc414120-e87f-4ec3-c57a-d8d5efab0932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "# Download a few different corpuses to work with GPT2\n",
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz'\n",
        "!tar -xvf text_files.tar.gz\n",
        "!rm text_files.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-06 17:33:49--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 34.237.183.157, 34.192.194.48, 34.231.49.99, ...\n",
            "Connecting to piazza.com (piazza.com)|34.237.183.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2020-02-06 17:33:49--  https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)... 54.230.18.161, 54.230.18.12, 54.230.18.115, ...\n",
            "Connecting to d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)|54.230.18.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-06 17:33:50 (10.1 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "text_files/lotr.txt\n",
            "text_files/\n",
            "text_files/alma.txt\n",
            "text_files/abcd.txt\n",
            "text_files/tiny_shakespeare.txt\n",
            "text_files/abab.txt\n",
            "text_files/switch.bat.txt\n",
            "text_files/switch.sh\n",
            "text_files/test1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg7SoAGkGh3Z",
        "colab_type": "code",
        "outputId": "a1180c48-c4c5-4b00-f9f7-bf8759debc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Download the children's book corpus from GitHub\n",
        "!wget -O cbt.txt https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/cbt_train.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 17:10:29--  https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/cbt_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25742364 (25M) [text/plain]\n",
            "Saving to: ‘cbt.txt’\n",
            "\n",
            "cbt.txt             100%[===================>]  24.55M  58.0MB/s    in 0.4s    \n",
            "\n",
            "2020-02-11 17:10:29 (58.0 MB/s) - ‘cbt.txt’ saved [25742364/25742364]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_JZMaHVEOg",
        "colab_type": "text"
      },
      "source": [
        "## Word Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx7LXT0sVLjI",
        "colab_type": "code",
        "outputId": "29eb8033-b897-4b5a-df67-372f069fd885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Download the simple word distribution from GitHub\n",
        "!wget -O word_dist_full.csv https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/word_dist_full.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 17:10:30--  https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/word_dist_full.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 163042 (159K) [text/plain]\n",
            "Saving to: ‘word_dist_full.csv’\n",
            "\n",
            "\rword_dist_full.csv    0%[                    ]       0  --.-KB/s               \rword_dist_full.csv  100%[===================>] 159.22K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-02-11 17:10:30 (7.22 MB/s) - ‘word_dist_full.csv’ saved [163042/163042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWVYaEVrV065",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordDist(Dataset):\n",
        "  def __init__(self):\n",
        "    self.df = pd.read_csv('word_dist_full.csv', header=None, names=['word', 'freq'])\n",
        "  \n",
        "  def getdf(self):\n",
        "    return self.df\n",
        "\n",
        "  def dict_normalized(self): \n",
        "    copy = self.df.copy()\n",
        "    copy['freq'] = copy['freq'] / copy['freq'].max()\n",
        "\n",
        "    return copy.set_index('word').to_dict()['freq']\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.df['word'][index], self.df['freq'][index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9LYBu6EVIkA",
        "colab_type": "text"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuQNroOuIg1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that deals with training and generating text from GPT2\n",
        "class LanguageModel():\n",
        "  def __init__(self, model='124M', genre='children', train_steps=200, max_length=150):\n",
        "    self.download_model(model)\n",
        "    self.genre = genre\n",
        "    self.max_length = max_length\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    self.sess = gpt2.start_tf_sess()\n",
        "\n",
        "    if genre == 'children':\n",
        "      gpt2.finetune(self.sess, 'cbt.txt', model_name=model, steps=train_steps)\n",
        "    else:\n",
        "      raise('The specified genre does not exist')\n",
        "\n",
        "  # Returns a list of sample texts with a given prefix and suffix\n",
        "  def generate_text(self, prefix='<|startoftext|>', suffix='.', include_prefix=False, nsamples=5):\n",
        "    if nsamples < 1 or nsamples > 20:\n",
        "      raise('Error: nsamples must be within the range 1 <= x <= 20')\n",
        "\n",
        "    return gpt2.generate(self.sess, prefix=prefix, truncate=suffix, include_prefix=include_prefix, batch_size=nsamples, nsamples=nsamples, return_as_list=True, length=self.max_length)\n",
        "  \n",
        "  def download_model(self, model_name):\n",
        "    if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "      print(f\"Downloading {model_name} model...\")\n",
        "      gpt2.download_gpt2(model_name=model_name)\n",
        "    else:\n",
        "      print(f\"{model_name} model is already downloaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQxMeo2JNzSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A class that contains some knowledge that the user has acquired over time.\n",
        "# For example, it may hold the words that the user knows (and how well the user knows them)\n",
        "class UserKnowledge():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # We will likely need some place to store the knowledge we acquire about the user\n",
        "  # so that we can access it from session to session\n",
        "  def save_knowledge(self, path):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK1wDhdgJajQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that evaluates sentences based on what the system knows about the user\n",
        "class SentenceEvaluator():\n",
        "  def __init__(self, level='beginner', user_knowledge=None):\n",
        "    self.level = 'beginner'\n",
        "    self.word_dist = WordDist().dict_normalized()\n",
        "    self.word_dist_threshold = 0.033\n",
        "    self.word_dist_threshold_step = 0.005\n",
        "    self.word_dist_difficulty_threshold = 7\n",
        "\n",
        "    if user_knowledge == None:\n",
        "      self.user_knowledge = UserKnowledge()\n",
        "    else:\n",
        "      self.user_knowledge = user_knowledge\n",
        "\n",
        "  # We will likely want some method to update the user_knowledge in the evaluator\n",
        "  # Maybe, we will only pass user_knowledge into the evaluate function?...\n",
        "  def update_user_knowledge(user_knowledge):\n",
        "    pass\n",
        "\n",
        "  # Score the sentences and return the sentence with the highest score\n",
        "  def evaluate(self, sentences):\n",
        "    scores = self.score(sentences)\n",
        "    high_score_index = np.argmax(scores)\n",
        "\n",
        "    return sentences[high_score_index]\n",
        "\n",
        "  # Score each sentence based on some criteria\n",
        "  def score(self, sentences):\n",
        "    scores = []\n",
        "    for sentence in sentences:\n",
        "      score = 0\n",
        "      score += self.length_score(sentence)\n",
        "      score += self.word_difficulty(sentence)\n",
        "\n",
        "      # add other criteria for scoring\n",
        "      # ...\n",
        "      # ...\n",
        "      scores.append(score)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "  # For beginners, we want to favor shorter sentences\n",
        "  # This method should change as we increase difficulty level\n",
        "  def length_score(self, sentence):\n",
        "    length = len(sentence)\n",
        "\n",
        "    if self.level == 'beginner':\n",
        "      if length > 0 and length <= 15:\n",
        "        return 6\n",
        "      elif length > 15 and length <= 25:\n",
        "        return 10\n",
        "      elif length > 25 and length <= 35:\n",
        "        return 7\n",
        "      elif length > 35 and length <= 45:\n",
        "        return 3\n",
        "      elif length > 45 and length <= 55:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "    else:\n",
        "      raise('support for non-beginners is not supported')\n",
        "\n",
        "  # For beginners, easier the better!\n",
        "  # This method should change as we increase difficulty level\n",
        "  def word_difficulty(self, sentence):\n",
        "    word_scores = []\n",
        "\n",
        "    for word in sentence.split(' '):\n",
        "      word = word.lower()\n",
        "      word_score = self.word_dist.get(word, 0) # Return the word or 0 if it doesn't exist\n",
        "\n",
        "      if word_score >= self.word_dist_threshold:\n",
        "        word_scores.append(10)\n",
        "      elif word_score >= self.word_dist_threshold - self.word_dist_threshold_step:\n",
        "        word_scores.append(8)\n",
        "      elif word_score >= self.word_dist_threshold - (2 * self.word_dist_threshold_step):\n",
        "        word_scores.append(6)\n",
        "      elif word_score >= self.word_dist_threshold - (3 * self.word_dist_threshold_step):\n",
        "        word_scores.append(4)\n",
        "      elif word_score >= self.word_dist_threshold - (4 * self.word_dist_threshold_step):\n",
        "        word_scores.append(2)\n",
        "      else:\n",
        "        word_scores.append(0)\n",
        "\n",
        "    score_med = np.median(word_scores)\n",
        "\n",
        "    if score_med >= self.word_dist_difficulty_threshold:\n",
        "      return 10\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 1:\n",
        "      return 8\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 2:\n",
        "      return 6\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 3:\n",
        "      return 4\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 4:\n",
        "      return 2\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVxCTzArHKdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGenerator():\n",
        "  def __init__(self, language_model=None, evaluator=None):\n",
        "    if language_model == None:\n",
        "      self.language_model = LanguageModel()\n",
        "    else:\n",
        "      self.language_model = language_model\n",
        "    if evaluator == None:\n",
        "      self.evaluator = SentenceEvaluator()\n",
        "    else:\n",
        "      self.evaluator = evaluator\n",
        "\n",
        "  # Generate a sentence, pick the best one based on evaluation, return the sentence\n",
        "  def generate(self, print_all_sentences=False):\n",
        "    # Determine the prefix/suffix based on some kind of criteria that is learned over time\n",
        "    prefix = self.determine_prefix()\n",
        "    if prefix == '<|startoftext|>':\n",
        "      include_prefix = False\n",
        "    else:\n",
        "      include_prefix = True\n",
        "    suffix = self.determine_suffix()\n",
        "\n",
        "    sentences = self.language_model.generate_text(prefix=prefix, suffix=suffix, include_prefix=include_prefix, nsamples=15)\n",
        "    sentences = self.filter_punctuation(sentences)\n",
        "    best_sentence = self.evaluator.evaluate(sentences)\n",
        "\n",
        "    if print_all_sentences:\n",
        "      for sentence in sentences:\n",
        "        print(sentence)\n",
        "\n",
        "    return best_sentence\n",
        "  \n",
        "  # Used to filter unwanted punctuation GPT2 might produce, like newlines\n",
        "  def filter_punctuation(self, sentences):\n",
        "    filtered_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "      new_sentence = sentence.replace('\\n', ' ')\n",
        "      new_sentence = new_sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "      filtered_sentences.append(new_sentence)\n",
        "\n",
        "    return filtered_sentences\n",
        "\n",
        "  def determine_prefix(self):\n",
        "    # Good simple sentence starters...\n",
        "    starters = ['I', 'You', 'The', 'They', 'It', '<|startoftext|>', 'He', 'She', 'My']\n",
        "    random_index = np.random.randint(0, len(starters)) \n",
        "\n",
        "    return starters[random_index]\n",
        "\n",
        "  def determine_suffix(self):\n",
        "    return '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpZvu9GMVu-O",
        "colab_type": "text"
      },
      "source": [
        "## Tutoring System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfeiyHvE2AhJ",
        "colab_type": "code",
        "outputId": "a1cd751d-f096-401f-c586-68925fd0833e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wd = WordDist().dict_normalized()\n",
        "wd['why']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008298837620262524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJB-19P2Rlh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LanguageModel('355M', train_steps=1000) # Will fine-tune model everytime this is called! -- Will need to be fixed at some point\n",
        "generator = SentenceGenerator(language_model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1d23JPQf7VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = SentenceGenerator(language_model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIEVzlnWc9EF",
        "colab_type": "code",
        "outputId": "72eb2be6-5206-4115-9205-c0be18e5eeb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "generator = SentenceGenerator(language_model=model)\n",
        "best_sentence = generator.generate(print_all_sentences=True)\n",
        "print(\"Best Sentence: \", best_sentence)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This week was a glorious one \n",
            "This is an old lady \n",
            "This not being so  she looked up  and saw  for the first time in her life  that her sister was really the pretty girl who loved her  and was the darling of all her family \n",
            "This  negligible  has what I would call a real moral effect \n",
            "This sure is a pretty mourner  for  though he is a simple fellow  he is a very hard working fellow  and a very patient fellow \n",
            "This  I think  is the only thing that will have any effect at all \n",
            "This was the place for a fool  but also for a twelveyearold boy \n",
            "This was the first of many humiliations that the old gentleman suffered during his entire life \n",
            "This \n",
            "This was very sweet  and I promised myself to give it to her \n",
            "Best Sentence:  This week was a glorious one \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5PrmYHIZL0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_options():\n",
        "  print('0: I don\\'t know what this means.')\n",
        "  print('1: Choose words I don\\'t know.')\n",
        "  print('2: Generate a better sentence.')\n",
        "  print('3: I need definitions.')\n",
        "  print('4: I understand! Give me another!')\n",
        "  print('5: Exit: I\\'ve learned enough for today.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh3HWeS6hLG8",
        "colab_type": "text"
      },
      "source": [
        "## Text-to-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uN47D4-hPTc",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/content/speech.mp3": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "b85d4b4f-8fa2-438d-de66-1f56b82f4f9f"
      },
      "source": [
        "text = 'Thanks for using Learn-A-Language! Let\\'s Learn!'\n",
        "speech = gTTS(text = text, lang = 'en', slow = False)\n",
        "speech.save('speech.mp3')\n",
        "Audio(filename='speech.mp3', autoplay=True)\n",
        "HTML('<audio controls><source src=\"speech.mp3\" type=\"/mp3\"></audio>')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<audio controls><source src=\"/content/speech.mp3\" type=\"audio/mp3\"></audio>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht56XkiOmoEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e57854da-f25a-44ff-e45d-e080e1d1f5b9"
      },
      "source": [
        "Audio('Hedidnotlikethesoundofit.mp3', autoplay=True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "something\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psl0v8GaeRBq",
        "colab_type": "text"
      },
      "source": [
        "## Learn-A-Language Loop\n",
        "* Terrible Name...\n",
        "* We need to come up with something!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT9XoYSjXnQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "outputId": "fe02ce7f-500c-46a5-9829-94b0a5a12cb2"
      },
      "source": [
        "print(\"Learn-A-Language - English\")\n",
        "\n",
        "while True:\n",
        "  print('\\nGenerating personalized sentence... Please Wait.')\n",
        "  sentence = generator.generate()\n",
        "  print(\"\\nTry this sentence:\")\n",
        "  print(sentence, '\\n')\n",
        "  speech = gTTS(text=sentence, lang='en', slow=False)\n",
        "  filename = sentence.replace(' ', '') + '.mp3'\n",
        "  speech.save(filename)\n",
        "  Audio(filename=filename, autoplay=False)\n",
        "\n",
        "  while True:\n",
        "    print_options()\n",
        "    code = input('Enter a code from above:')\n",
        "    if code in ['0','1','2','3','4','5']:\n",
        "      code = int(code)\n",
        "      break\n",
        "    print('')\n",
        "  \n",
        "  if code == 0:\n",
        "    print('\\nI\\'m Sorry! This is as get as it gets...')\n",
        "  elif code == 1:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 2:\n",
        "    print('\\nNew sentence coming right up!')\n",
        "  elif code == 3:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 4:\n",
        "    print('\\nGreat Job! Here\\'s another.')\n",
        "  else:\n",
        "    print('\\nThanks for using Learn-A-Language! Play again soon!')\n",
        "    break"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn-A-Language - English\n",
            "\n",
            "Generating personalized sentence... Please Wait.\n",
            "\n",
            "Try this sentence:\n",
            "He did not like the sound of it  \n",
            "\n",
            "0: I don't know what this means.\n",
            "1: Choose words I don't know.\n",
            "2: Generate a better sentence.\n",
            "3: I need definitions.\n",
            "4: I understand! Give me another!\n",
            "5: Exit: I've learned enough for today.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6421a3d1a441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter a code from above:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}