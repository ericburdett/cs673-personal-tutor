{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal-Tutor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs673-personal-tutor/blob/master/Personal_Tutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPwFJK2Q3is",
        "colab_type": "text"
      },
      "source": [
        "# Personal Tutor\n",
        "\n",
        "This notebook contains code for the Personal Tutor System built for CS673: Computational Creativity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVLsHt3cguG_",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Setup\n",
        "\n",
        "Installing transformers requires the Runtime to be restarted on Colab. The os.kill command does that for us automatically. Just note that Colab will show an error indicating that the runtime has crashed... Ignore it and run the following code blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rObf9AtbBg0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!python -m spacy download en_core_web_md\n",
        "import os\n",
        "os.kill(os.getpid(), 9) # This will automatically restart the runtime. Colab will show an error... but it works"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geqLGvzog5eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pdb\n",
        "import string\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_JZMaHVEOg",
        "colab_type": "text"
      },
      "source": [
        "## Word Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx7LXT0sVLjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the simple word distribution from GitHub\n",
        "!wget -O word_dist_full.csv https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/word_dist_full.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWVYaEVrV065",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordDist():\n",
        "  def __init__(self):\n",
        "    self.df = pd.read_csv('word_dist_full.csv', header=None, names=['word', 'freq'])\n",
        "  \n",
        "  def getdf(self):\n",
        "    return self.df\n",
        "\n",
        "  def dict_normalized(self): \n",
        "    copy = self.df.copy()\n",
        "    copy['freq'] = copy['freq'] / copy['freq'].max()\n",
        "\n",
        "    return copy.set_index('word').to_dict()['freq']\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.df['word'][index], self.df['freq'][index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoHU-CcRhB2V",
        "colab_type": "text"
      },
      "source": [
        "## Language Model and Evaluation Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCnqEfFwhiX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageModel():\n",
        "  def __init__(self, mask=None, k=50):\n",
        "    self.model = GPT2LMHeadModel.from_pretrained('distilgpt2').cuda()\n",
        "    self.tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
        "    self.k = k\n",
        "\n",
        "    if mask == None:\n",
        "      self.mask = torch.ones(len(self.tokenizer.get_vocab())).cuda()\n",
        "    else:\n",
        "      self.mask = torch.tensor(mask).cuda()\n",
        "\n",
        "  def top_k_logits(self, logits):\n",
        "    if self.k == 0:\n",
        "        return logits\n",
        "    values, _ = torch.topk(logits, self.k)\n",
        "    min_values = values[-1]\n",
        "    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n",
        "  \n",
        "  def tokenizer(self):\n",
        "    return self.tokenizer\n",
        "\n",
        "  def set_mask(self, mask):\n",
        "    self.mask = torch.tensor(mask).cuda()\n",
        "\n",
        "  def get_sentences(self, prompt, sentence_length, num_sentences):\n",
        "    sentences = []\n",
        "\n",
        "    for i in range(num_sentences):\n",
        "      sentence = self.get_sentence(prompt, sentence_length)\n",
        "      sentences.append(sentence)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "  def get_sentence(self, prompt, length):\n",
        "    generated = self.tokenizer.encode(prompt)\n",
        "    context = torch.tensor([generated]).cuda()\n",
        "\n",
        "    past = None\n",
        "\n",
        "    for i in range(length):\n",
        "      output, past = self.model(context, past=past)\n",
        "      \n",
        "      logits = output[..., -1, :].squeeze()\n",
        "      logits = logits * self.mask # Apply the mask to the logits\n",
        "\n",
        "      topk_logits = self.top_k_logits(logits)\n",
        "      topk_log_probs = F.softmax(topk_logits, dim=-1)\n",
        "      token = torch.multinomial(topk_log_probs, num_samples=1)\n",
        "\n",
        "      generated += [token.item()]\n",
        "      context = token.unsqueeze(0)\n",
        "    \n",
        "    sequence = self.tokenizer.decode(generated)\n",
        "\n",
        "    end_index = len(prompt.split('. '))\n",
        "\n",
        "    return \".\".join(sequence.split('.')[0:end_index]) + '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6916GMHuZMYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluator():\n",
        "  def __init__(self, topic):\n",
        "    self.topic_doc = NLP(topic)\n",
        "\n",
        "  def get_keywords(self, sentence_doc):\n",
        "    # Find Nouns and Adjectives\n",
        "    keywords = []\n",
        "    for token in sentence_doc:\n",
        "      pos = token.pos\n",
        "      if pos in [92, 96]: # NOUN, PNOUN, ADJ , 84\n",
        "         keywords.append(token)\n",
        "    \n",
        "    return keywords\n",
        "\n",
        "  def get_random_pairs(self, arr, size):\n",
        "    pairs = []\n",
        "\n",
        "    try:\n",
        "      for i in range(size):\n",
        "        pair = np.random.choice(arr, size=2, replace=False)\n",
        "        pairs.append(pair)\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "    return pairs\n",
        "\n",
        "  def generate_scores_array(self, size):\n",
        "    step = size // 10 + 1\n",
        "    return np.array([i for i in range(11) for _ in range(step)])[::-1][:size]\n",
        "  \n",
        "  def get_score(self, sentences, eval_func, negate=False):\n",
        "    lengths = [eval_func(sentence) for sentence in sentences]\n",
        "    sort_indices = np.argsort(np.negative(lengths)) if negate else np.argsort(lengths)\n",
        "    scores = self.generate_scores_array(len(sentences))\n",
        "    np.put(scores, sort_indices, scores)\n",
        "    return scores\n",
        "\n",
        "  def sentence_length_score(self, sentences):\n",
        "    return self.get_score(sentences, len, negate=False)\n",
        "\n",
        "  def topic_score(self, sentences):\n",
        "    return self.get_score(sentences, self.single_topic_score, negate=True)\n",
        "\n",
        "  def related_score(self, sentences):\n",
        "    return self.get_score(sentences, self.single_related_score, negate=True)\n",
        "\n",
        "  def score_sentences(self, sentences):\n",
        "    nlp_sentences = [NLP(sentence) for sentence in sentences]\n",
        "\n",
        "    scores = []\n",
        "    scores.append(self.sentence_length_score(sentences))\n",
        "    scores.append(self.topic_score(nlp_sentences))\n",
        "    scores.append(self.related_score(nlp_sentences))\n",
        "    # Append scores here for more tests\n",
        "\n",
        "    return np.mean(scores, axis=0)\n",
        "\n",
        "  def single_topic_score(self, sentence_doc):\n",
        "    keywords = self.get_keywords(sentence_doc)\n",
        "    if len(keywords) < 2:\n",
        "      return 0\n",
        "\n",
        "    similarities = []\n",
        "    for keyword in keywords:\n",
        "      if keyword.vector_norm:\n",
        "        similarity = self.topic_doc.similarity(keyword)\n",
        "      else:\n",
        "        similarity = 0\n",
        "\n",
        "      similarities.append(similarity)\n",
        "\n",
        "    return np.mean(similarities)\n",
        "  \n",
        "  def single_related_score(self, sentence_doc):\n",
        "    keywords = self.get_keywords(sentence_doc)\n",
        "\n",
        "    # Sample Random Pairs\n",
        "    pairs = self.get_random_pairs(keywords, 10) # 10 seems like a good number for now...\n",
        "    if pairs == None or len(pairs) == 0:\n",
        "      return 0\n",
        "\n",
        "    if len(keywords) != len(set(keywords)): # If the list contains duplicates, give poor score\n",
        "      return 0\n",
        "\n",
        "    # Check Similarity\n",
        "    similarities = []\n",
        "    for pair in pairs:\n",
        "\n",
        "      if pair[0].vector_norm and pair[1].vector_norm:\n",
        "        similarity = pair[0].similarity(pair[1])\n",
        "      else:\n",
        "        similarity = 0\n",
        "\n",
        "      if similarity >= 1: # Do not give a high similarity score if we are comparing a word with itself\n",
        "        similarity = 0\n",
        "\n",
        "      similarities.append(similarity)\n",
        "      # print('Comparing {} with {}, score: {:.4f}'.format(pair[0], pair[1], similarity))\n",
        "    \n",
        "    # print(similarities)\n",
        "\n",
        "    return np.mean(similarities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE9kVYrcTU9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_prompt(sentence, prompt):\n",
        "  new_sentence = sentence.split(prompt)\n",
        "  if len(new_sentence) < 2:\n",
        "    return ''\n",
        "  else:\n",
        "    return sentence.split(prompt)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcFuG14Tjkk1",
        "colab_type": "text"
      },
      "source": [
        "## User Knowledge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ77j4TChU7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordMemory:\n",
        "  def __init__(self, rank, memory_size=10):\n",
        "    self.rank = rank\n",
        "    self.memory_size = memory_size\n",
        "    self.memory = np.zeros(memory_size).tolist()\n",
        "\n",
        "  def add(self, is_known):\n",
        "    assert type(is_known) is bool # For now, only allow bools to be added to memory\n",
        "\n",
        "    self.memory.append(int(is_known))\n",
        "    if len(self.memory) > self.memory_size: # We are only remembering the past 'memory_size' times we've seen this word \n",
        "      self.memory.pop(0)\n",
        "\n",
        "  def ratio(self):\n",
        "    if len(self.memory) == 0:\n",
        "      return -1 # indicates the word has never been seen by the user\n",
        "    else:\n",
        "      return np.mean(self.memory)\n",
        "\n",
        "  def rank(self):\n",
        "    return self.rank"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nbI5uMalbQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UserKnowledge:\n",
        "  def __init__(self, vocabulary_list, tokenizer, window=500, lower_bound=.8, upper_bound=1.):\n",
        "    # contains dictionary of word : WordMemoryObject\n",
        "    self.knowledge = dict([(word, WordMemory(rank=index)) for index, word in enumerate(vocabulary_list)])\n",
        "    self.ranking = dict([(index, word) for index, word in enumerate(vocabulary_list)])\n",
        "    self.tokenizer = tokenizer\n",
        "    self.tokenizer_vocab = tokenizer.get_vocab()\n",
        "\n",
        "    self.window = window\n",
        "    self.lower_bound = lower_bound\n",
        "    self.upper_bound = upper_bound\n",
        "\n",
        "  def update(self, words, knowns):\n",
        "    for word, known in zip(words, knowns):\n",
        "      if word in self.knowledge: # Check first if the word exists in the dictionary\n",
        "        self.knowledge[word].add(known)\n",
        "      # else: ## TODO ##\n",
        "      #   Possibly add it to the knowledge base and then give it more likelihood to be shown again...\n",
        "  \n",
        "  def compute_ratios(self): # Known/Total\n",
        "    return dict([(word, memory.ratio()) for word, memory in self.knowledge.items()])\n",
        "  \n",
        "  def compute_mask(self):\n",
        "    mask = np.ones(len(self.tokenizer_vocab))\n",
        "    indices = []\n",
        "    current_num = 0\n",
        "\n",
        "    # Give higher probability to punctuation so we don't end up with really long sentences\n",
        "    punc_indices = []\n",
        "    punc_indices.append(self.tokenizer_vocab[self.tokenizer.tokenize(\".\")[0]])\n",
        "    # punc_indices.append(self.tokenizer_vocab[self.tokenizer.tokenize(\",\")[0]])\n",
        "    punc_indices.append(self.tokenizer_vocab[self.tokenizer.tokenize(\"!\")[0]])\n",
        "    # punc_indices.append(self.tokenizer_vocab[self.tokenizer.tokenize(\";\")[0]])\n",
        "\n",
        "    for mask_index in punc_indices:\n",
        "      mask[mask_index] = self.lower_bound - .05\n",
        "\n",
        "    # Iterate through the rankings in order...\n",
        "    for index, word in self.ranking.items():\n",
        "      # if current_num <= self.window:\n",
        "        # print(word, ',', current_num)\n",
        "\n",
        "      # Get tokens for the given word with a space pre-pended and also with the word capitalized\n",
        "      tokens_low = self.tokenizer.tokenize(' ' + str(word))\n",
        "      tokens_up = self.tokenizer.tokenize(' ' + str(word).capitalize())\n",
        "\n",
        "      tokens = np.concatenate((tokens_low, tokens_up))\n",
        "      tokens = list(set(tokens)) # Give us only the unique tokens\n",
        "\n",
        "      mask_indices = []\n",
        "      for token in tokens:\n",
        "        mask_indices.append(self.tokenizer_vocab[token])\n",
        "\n",
        "      # if the user hasn't learned a given word, give it a higher probability for the language model to produce it\n",
        "      # if we still need to fill the window, try the most frequent words first\n",
        "      # as the user learns the easier words, the more difficult words will become more probable\n",
        "      ratio = self.knowledge[word].ratio()\n",
        "      if ratio != 1.0 and current_num <= self.window:\n",
        "        mask_value = self.lower_bound\n",
        "        current_num += 1\n",
        "      else:\n",
        "        mask_value = self.upper_bound\n",
        "\n",
        "      for mask_index in mask_indices:\n",
        "        if (mask_value != 1):\n",
        "          indices.append(mask_index)\n",
        "          mask[mask_index] = mask_value\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7voeGBo1SsA6",
        "colab_type": "text"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdHhxDUhBmeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick your topic\n",
        "# Set up objects for system\n",
        "TOPIC = 'News'\n",
        "\n",
        "NLP = spacy.load('en_core_web_md')\n",
        "LM = LanguageModel(k=25)\n",
        "EVAL = Evaluator(TOPIC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqyfBz4M89HP",
        "colab_type": "text"
      },
      "source": [
        "### Basic Model without UserKnowledge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYjUir_bBJZc",
        "colab_type": "code",
        "outputId": "3aae0cfc-72b8-4d4b-9d82-d3856d359092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Main App Loop\n",
        "NUM_SENTENCES = 10\n",
        "MAX_SENTENCE_LENGTH = 40\n",
        "\n",
        "LM.set_mask(np.ones(len(LM.tokenizer.get_vocab())))\n",
        "\n",
        "prompts = ['President Trump said']\n",
        "prompts_truncate = [False]\n",
        "\n",
        "rand_index = np.random.randint(len(prompts))\n",
        "prompt = prompts[rand_index]\n",
        "should_truncate = prompts_truncate[rand_index]\n",
        "\n",
        "sentences = LM.get_sentences(prompt, MAX_SENTENCE_LENGTH, NUM_SENTENCES)\n",
        "if should_truncate:\n",
        "  sentences = [remove_prompt(sentence, prompt) for sentence in sentences]\n",
        "\n",
        "scores = EVAL.score_sentences(sentences)\n",
        "print('Produced Sentence: ', sentences[np.argmax(scores)])"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Produced Sentence:  President Trump said this week that his administration was committed to ensuring that women get the healthcare they want.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsUYw1Xb83Dc",
        "colab_type": "text"
      },
      "source": [
        "### Using UserKnowledge to Modify Probability Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyna1Q9h5gOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "619d50b4-eb22-4098-c459-1fce1c051338"
      },
      "source": [
        "# Main App Loop\n",
        "NUM_SENTENCES = 10\n",
        "MAX_SENTENCE_LENGTH = 40\n",
        "\n",
        "user_knowledge = UserKnowledge(WordDist().dict_normalized(), LM.tokenizer)\n",
        "# Use user_knowledge.update() to update known words -- accepts list of words and list of bools indicating known/unknown\n",
        "mask = user_knowledge.compute_mask() # Run this function to compute the mask\n",
        "LM.set_mask(mask) # Set the mask to the language model\n",
        "\n",
        "prompts = ['President Trump said']\n",
        "prompts_truncate = [False]\n",
        "\n",
        "rand_index = np.random.randint(len(prompts))\n",
        "prompt = prompts[rand_index]\n",
        "should_truncate = prompts_truncate[rand_index]\n",
        "\n",
        "sentences = LM.get_sentences(prompt, MAX_SENTENCE_LENGTH, NUM_SENTENCES)\n",
        "if should_truncate:\n",
        "  sentences = [remove_prompt(sentence, prompt) for sentence in sentences]\n",
        "\n",
        "scores = EVAL.score_sentences(sentences)\n",
        "print('Produced Sentence: ', sentences[np.argmax(scores)])"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Produced Sentence:  President Trump said during a news visit this week that he will not be in office.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWMZfZXvCgsc",
        "colab_type": "text"
      },
      "source": [
        "### Example of updating user_knowledge object and computing mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZ2RHf-fPbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of updating user_knowledge\n",
        "user_knowledge = UserKnowledge(WordDist().dict_normalized(), LM.tokenizer)\n",
        "user_knowledge.update(['the', 'the', 'a', 'from'], [True, False, True, True])\n",
        "mask = user_knowledge.compute_mask()\n",
        "# LM.set_mask(mask) # We can update the language model's mask with the set_mask method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2TJoUJPqaqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokens that we modified that have a higher probability of being shown\n",
        "tokenizer.convert_ids_to_tokens(np.squeeze(np.where(mask != 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs19o8d-OOZW",
        "colab_type": "text"
      },
      "source": [
        "# Old Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzpCKzikWxA3",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn2-Iv5RGY_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gpt-2-simple\n",
        "!pip install gtts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUN5YCJsWzAs",
        "colab_type": "code",
        "outputId": "99396b8d-283e-4794-f381-8364992aa60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import string\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import gpt_2_simple as gpt2\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from gtts import gTTS \n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from IPython.display import Audio, HTML\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg7SoAGkGh3Z",
        "colab_type": "code",
        "outputId": "3d69a046-0b9e-4c70-b62c-63b01ab86661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Download the children's book corpus from GitHub\n",
        "!wget -O wiki_simple.txt https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/wiki_simple.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 18:26:35--  https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/wiki_simple.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47667422 (45M) [text/plain]\n",
            "Saving to: ‘wiki_simple.txt’\n",
            "\n",
            "wiki_simple.txt     100%[===================>]  45.46M   199MB/s    in 0.2s    \n",
            "\n",
            "2020-02-20 18:26:36 (199 MB/s) - ‘wiki_simple.txt’ saved [47667422/47667422]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9LYBu6EVIkA",
        "colab_type": "text"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuQNroOuIg1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that deals with training and generating text from GPT2\n",
        "class LanguageModel():\n",
        "  def __init__(self, model='124M', genre='children', train_steps=200, max_length=150):\n",
        "    self.download_model(model)\n",
        "    self.genre = genre\n",
        "    self.max_length = max_length\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    self.sess = gpt2.start_tf_sess()\n",
        "\n",
        "    if genre == 'children':\n",
        "      gpt2.finetune(self.sess, 'wiki_simple.txt', model_name=model, steps=train_steps)\n",
        "    else:\n",
        "      raise('The specified genre does not exist')\n",
        "\n",
        "  # Returns a list of sample texts with a given prefix and suffix\n",
        "  def generate_text(self, prefix='<|startoftext|>', suffix='.', include_prefix=False, nsamples=5):\n",
        "    if nsamples < 1 or nsamples > 20:\n",
        "      raise('Error: nsamples must be within the range 1 <= x <= 20')\n",
        "\n",
        "    return gpt2.generate(self.sess, prefix=prefix, truncate=suffix, include_prefix=include_prefix, batch_size=nsamples, nsamples=nsamples, return_as_list=True, length=self.max_length)\n",
        "  \n",
        "  def download_model(self, model_name):\n",
        "    if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "      print(f\"Downloading {model_name} model...\")\n",
        "      gpt2.download_gpt2(model_name=model_name)\n",
        "    else:\n",
        "      print(f\"{model_name} model is already downloaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQxMeo2JNzSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A class that contains some knowledge that the user has acquired over time.\n",
        "# For example, it may hold the words that the user knows (and how well the user knows them)\n",
        "class UserKnowledge():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # We will likely need some place to store the knowledge we acquire about the user\n",
        "  # so that we can access it from session to session\n",
        "  def save_knowledge(self, path):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK1wDhdgJajQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that evaluates sentences based on what the system knows about the user\n",
        "class SentenceEvaluator():\n",
        "  def __init__(self, level='beginner', user_knowledge=None):\n",
        "    self.level = 'beginner'\n",
        "    self.word_dist = WordDist().dict_normalized()\n",
        "    self.word_dist_threshold = 0.033\n",
        "    self.word_dist_threshold_step = 0.005\n",
        "    self.word_dist_difficulty_threshold = 7\n",
        "\n",
        "    if user_knowledge == None:\n",
        "      self.user_knowledge = UserKnowledge()\n",
        "    else:\n",
        "      self.user_knowledge = user_knowledge\n",
        "\n",
        "  # We will likely want some method to update the user_knowledge in the evaluator\n",
        "  # Maybe, we will only pass user_knowledge into the evaluate function?...\n",
        "  def update_user_knowledge(user_knowledge):\n",
        "    pass\n",
        "\n",
        "  # Score the sentences and return the sentence with the highest score\n",
        "  def evaluate(self, sentences):\n",
        "    scores = self.score(sentences)\n",
        "    high_score_index = np.argmax(scores)\n",
        "\n",
        "    return sentences[high_score_index]\n",
        "\n",
        "  # Score each sentence based on some criteria\n",
        "  def score(self, sentences):\n",
        "    scores = []\n",
        "    for sentence in sentences:\n",
        "      score = 0\n",
        "      score += self.length_score(sentence)\n",
        "      score += self.word_difficulty(sentence)\n",
        "\n",
        "      # add other criteria for scoring\n",
        "      # ...\n",
        "      # ...\n",
        "      scores.append(score)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "  # For beginners, we want to favor shorter sentences\n",
        "  # This method should change as we increase difficulty level\n",
        "  def length_score(self, sentence):\n",
        "    length = len(sentence)\n",
        "\n",
        "    if self.level == 'beginner':\n",
        "      if length > 0 and length <= 15:\n",
        "        return 6\n",
        "      elif length > 15 and length <= 25:\n",
        "        return 10\n",
        "      elif length > 25 and length <= 35:\n",
        "        return 7\n",
        "      elif length > 35 and length <= 45:\n",
        "        return 3\n",
        "      elif length > 45 and length <= 55:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "    else:\n",
        "      raise('support for non-beginners is not supported')\n",
        "\n",
        "  # For beginners, easier the better!\n",
        "  # This method should change as we increase difficulty level\n",
        "  def word_difficulty(self, sentence):\n",
        "    word_scores = []\n",
        "\n",
        "    for word in sentence.split(' '):\n",
        "      word = word.lower()\n",
        "      word_score = self.word_dist.get(word, 0) # Return the word or 0 if it doesn't exist\n",
        "\n",
        "      if word_score >= self.word_dist_threshold:\n",
        "        word_scores.append(10)\n",
        "      elif word_score >= self.word_dist_threshold - self.word_dist_threshold_step:\n",
        "        word_scores.append(8)\n",
        "      elif word_score >= self.word_dist_threshold - (2 * self.word_dist_threshold_step):\n",
        "        word_scores.append(6)\n",
        "      elif word_score >= self.word_dist_threshold - (3 * self.word_dist_threshold_step):\n",
        "        word_scores.append(4)\n",
        "      elif word_score >= self.word_dist_threshold - (4 * self.word_dist_threshold_step):\n",
        "        word_scores.append(2)\n",
        "      else:\n",
        "        word_scores.append(0)\n",
        "\n",
        "    score_med = np.median(word_scores)\n",
        "\n",
        "    if score_med >= self.word_dist_difficulty_threshold:\n",
        "      return 10\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 1:\n",
        "      return 8\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 2:\n",
        "      return 6\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 3:\n",
        "      return 4\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 4:\n",
        "      return 2\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVxCTzArHKdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGenerator():\n",
        "  def __init__(self, language_model=None, evaluator=None):\n",
        "    if language_model == None:\n",
        "      self.language_model = LanguageModel()\n",
        "    else:\n",
        "      self.language_model = language_model\n",
        "    if evaluator == None:\n",
        "      self.evaluator = SentenceEvaluator()\n",
        "    else:\n",
        "      self.evaluator = evaluator\n",
        "\n",
        "  # Generate a sentence, pick the best one based on evaluation, return the sentence\n",
        "  def generate(self, print_all_sentences=False):\n",
        "    # Determine the prefix/suffix based on some kind of criteria that is learned over time\n",
        "    prefix = self.determine_prefix()\n",
        "    if prefix == '<|startoftext|>':\n",
        "      include_prefix = False\n",
        "    else:\n",
        "      include_prefix = True\n",
        "    suffix = self.determine_suffix()\n",
        "\n",
        "    sentences = self.language_model.generate_text(prefix=prefix, suffix=suffix, include_prefix=include_prefix, nsamples=15)\n",
        "    sentences = self.filter_punctuation(sentences)\n",
        "    best_sentence = self.evaluator.evaluate(sentences)\n",
        "\n",
        "    if print_all_sentences:\n",
        "      for sentence in sentences:\n",
        "        print(sentence)\n",
        "\n",
        "    return best_sentence\n",
        "  \n",
        "  # Used to filter unwanted punctuation GPT2 might produce, like newlines\n",
        "  def filter_punctuation(self, sentences):\n",
        "    filtered_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "      new_sentence = sentence.replace('\\n', ' ')\n",
        "      new_sentence = new_sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "      filtered_sentences.append(new_sentence)\n",
        "\n",
        "    return filtered_sentences\n",
        "\n",
        "  def determine_prefix(self):\n",
        "    # Good simple sentence starters...\n",
        "    # starters = ['<|startoftext|>']\n",
        "    starters = ['I', 'You', 'The', 'They', 'It', '<|startoftext|>', 'He', 'She', 'My']\n",
        "    random_index = np.random.randint(0, len(starters)) \n",
        "\n",
        "    return starters[random_index]\n",
        "\n",
        "  def determine_suffix(self):\n",
        "    return '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpZvu9GMVu-O",
        "colab_type": "text"
      },
      "source": [
        "## Tutoring System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJB-19P2Rlh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LanguageModel('117M', train_steps=200) # Will fine-tune model everytime this is called! -- Will need to be fixed at some point"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIEVzlnWc9EF",
        "colab_type": "code",
        "outputId": "1baf679a-474a-4a27-9b88-f6119beaa1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "generator = SentenceGenerator(language_model=model)\n",
        "best_sentence = generator.generate(print_all_sentences=True)\n",
        "print(\"Best Sentence: \", best_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My own experience with it was that it was a very funny and funny movie \n",
            "My game is an open world game \n",
            "My second favorite place to eat is at a nearby lake \n",
            "My name is Washington SmootHart  and I am an agent of the United Nations \n",
            "Myrious s talk with the King of France was not well received and the book was banned \n",
            "My wife and her brother were at home when a sudden  thunderbolt  struck the house \n",
            "My money was full of things that are not in the movie and were not intended for audience or to be seen by children \n",
            "My favorite game is High Roller Ballet \n",
            "My own life was spent in the city and in the West Bank  and belonged to the family of the people who lived there \n",
            "My hair is round and it looks like the shaft of a gun \n",
            "My way was to go to a village called Namur in Afghanistan in 1959 \n",
            "My students were supposed to be students at the University of East Anglia  but they were supposed to be studying in the department of English \n",
            "My statutes were changed to go with the Dukes of France  and the Duke of Normandy  who was Grand Duke of Austria \n",
            "My precious mama and I were taken to a hospital in India \n",
            "My clan was part of the Second Temple of Jerusalem \n",
            "Best Sentence:  My hair is round and it looks like the shaft of a gun \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5PrmYHIZL0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_options():\n",
        "  print('0: I don\\'t know what this means.')\n",
        "  print('1: Choose words I don\\'t know.')\n",
        "  print('2: Generate a better sentence.')\n",
        "  print('3: I need definitions.')\n",
        "  print('4: I understand! Give me another!')\n",
        "  print('5: Exit: I\\'ve learned enough for today.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh3HWeS6hLG8",
        "colab_type": "text"
      },
      "source": [
        "## Text-to-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uN47D4-hPTc",
        "colab_type": "code",
        "outputId": "9ee909db-08e4-46d4-a4d3-188ff06f33cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "speech = gTTS(text = best_sentence, lang = 'en', slow = False)\n",
        "speech.save('speech.mp3')\n",
        "Audio(filename='speech.mp3', autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht56XkiOmoEu",
        "colab_type": "code",
        "outputId": "e57854da-f25a-44ff-e45d-e080e1d1f5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Audio('Hedidnotlikethesoundofit.mp3', autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "something\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psl0v8GaeRBq",
        "colab_type": "text"
      },
      "source": [
        "## Learn-A-Language Loop\n",
        "* Terrible Name...\n",
        "* We need to come up with something!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fe02ce7f-500c-46a5-9829-94b0a5a12cb2",
        "id": "PxyjwQtX3Het",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        }
      },
      "source": [
        "print(\"Learn-A-Language - English\")\n",
        "\n",
        "while True:\n",
        "  print('\\nGenerating personalized sentence... Please Wait.')\n",
        "  sentence = generator.generate()\n",
        "  print(\"\\nTry this sentence:\")\n",
        "  print(sentence, '\\n')\n",
        "  speech = gTTS(text=sentence, lang='en', slow=False)\n",
        "  filename = sentence.replace(' ', '') + '.mp3'\n",
        "  speech.save(filename)\n",
        "  \n",
        "\n",
        "  while True:\n",
        "    print_options()\n",
        "    Audio(filename=filename, autoplay=False)\n",
        "    code = input('Enter a code from above:')\n",
        "    if code in ['0','1','2','3','4','5']:\n",
        "      code = int(code)\n",
        "      break\n",
        "    print('')\n",
        "  \n",
        "  if code == 0:\n",
        "    print('\\nI\\'m Sorry! This is as get as it gets...')\n",
        "  elif code == 1:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 2:\n",
        "    print('\\nNew sentence coming right up!')\n",
        "  elif code == 3:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 4:\n",
        "    print('\\nGreat Job! Here\\'s another.')\n",
        "  else:\n",
        "    print('\\nThanks for using Learn-A-Language! Play again soon!')\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn-A-Language - English\n",
            "\n",
            "Generating personalized sentence... Please Wait.\n",
            "\n",
            "Try this sentence:\n",
            "He did not like the sound of it  \n",
            "\n",
            "0: I don't know what this means.\n",
            "1: Choose words I don't know.\n",
            "2: Generate a better sentence.\n",
            "3: I need definitions.\n",
            "4: I understand! Give me another!\n",
            "5: Exit: I've learned enough for today.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6421a3d1a441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter a code from above:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT9XoYSjXnQ1",
        "colab_type": "code",
        "outputId": "fe02ce7f-500c-46a5-9829-94b0a5a12cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        }
      },
      "source": [
        "print(\"Learn-A-Language - English\")\n",
        "\n",
        "while True:\n",
        "  print('\\nGenerating personalized sentence... Please Wait.')\n",
        "  sentence = generator.generate()\n",
        "  print(\"\\nTry this sentence:\")\n",
        "  print(sentence, '\\n')\n",
        "  speech = gTTS(text=sentence, lang='en', slow=False)\n",
        "  filename = sentence.replace(' ', '') + '.mp3'\n",
        "  speech.save(filename)\n",
        "  Audio(filename=filename, autoplay=False)\n",
        "\n",
        "  while True:\n",
        "    print_options()\n",
        "    Audio(filename=filename, autoplay=False)\n",
        "    code = input('Enter a code from above:')\n",
        "    if code in ['0','1','2','3','4','5']:\n",
        "      code = int(code)\n",
        "      break\n",
        "    print('')\n",
        "  \n",
        "  if code == 0:\n",
        "    print('\\nI\\'m Sorry! This is as good as it gets...')\n",
        "  elif code == 1:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 2:\n",
        "    print('\\nNew sentence coming right up!')\n",
        "  elif code == 3:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 4:\n",
        "    print('\\nGreat Job! Here\\'s another.')\n",
        "  else:\n",
        "    print('\\nThanks for using Learn-A-Language! Play again soon!')\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn-A-Language - English\n",
            "\n",
            "Generating personalized sentence... Please Wait.\n",
            "\n",
            "Try this sentence:\n",
            "He did not like the sound of it  \n",
            "\n",
            "0: I don't know what this means.\n",
            "1: Choose words I don't know.\n",
            "2: Generate a better sentence.\n",
            "3: I need definitions.\n",
            "4: I understand! Give me another!\n",
            "5: Exit: I've learned enough for today.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6421a3d1a441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter a code from above:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}