{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal-Tutor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8kP7URKg7ZI0mHUzRHTpA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs673-personal-tutor/blob/master/Personal_Tutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPwFJK2Q3is",
        "colab_type": "text"
      },
      "source": [
        "# Personal Tutor\n",
        "\n",
        "This notebook contains code for the Personal Tutor System built for CS673: Computational Creativity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rObf9AtbBg0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "b612eb04-6249-4ffc-b4a0-29b8b3f398f1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 51.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 60.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=ef2de0530782482eb7f117ba2f8c0d3c3d91db03af80e0c0158b1e8bd0a6006a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1iYQ01aM3cU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f907d98e-dbb5-4ff5-ded3-7398de1e4328"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auC2gjwWBqR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0573c512-b3f8-4001-9ab1-17732c7558f9"
      },
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Encode a text inputs\n",
        "text = \"Computational Creativity is\"\n",
        "indexed_tokens = tokenizer.encode(text)\n",
        "\n",
        "# Convert indexed tokens in a PyTorch tensor\n",
        "tokens_tensor = torch.tensor([indexed_tokens])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlUhYpwqHUtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a12a9057-63a2-48a4-9f32-d5ce527dc437"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Set the model in evaluation mode to deactivate the DropOut modules\n",
        "# This is IMPORTANT to have reproducible results during evaluation!\n",
        "model.eval()\n",
        "\n",
        "# If you have a GPU, put everything on cuda\n",
        "tokens_tensor = tokens_tensor.to('cuda')\n",
        "model.to('cuda')\n",
        "\n",
        "# Predict all tokens\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]\n",
        "\n",
        "# get the predicted next sub-word (in our case, the word 'man')\n",
        "pdb.set_trace()\n",
        "\n",
        "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
        "print(predicted_text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "INFO:transformers.configuration_utils:Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--Return--\n",
            "> <ipython-input-21-61ac3f967e49>(17)<module>()->None\n",
            "-> pdb.set_trace()\n",
            "(Pdb) predictions.shape\n",
            "torch.Size([1, 6, 50257])\n",
            "(Pdb) predictions[0][-1].shape\n",
            "torch.Size([50257])\n",
            "(Pdb) a = torch.argmax(predictions[0][-1])\n",
            "(Pdb) a\n",
            "(Pdb) print(a)\n",
            "*** NameError: name 'a' is not defined\n",
            "(Pdb) print(torch.argmax(predictions[0][-1])\n",
            "*** SyntaxError: unexpected EOF while parsing\n",
            "(Pdb) print(torch.argmax(predictions[0][-1]))\n",
            "tensor(257, device='cuda:0')\n",
            "(Pdb) tokenizer.decode(257)\n",
            "' a'\n",
            "(Pdb) tokenizer.decode(0)\n",
            "'!'\n",
            "(Pdb) tokenizer.decode(-1)\n",
            "*** TypeError: 'NoneType' object is not iterable\n",
            "(Pdb) tokenizer.decode(1)\n",
            "'\"'\n",
            "(Pdb) tokenizer.decode(2)\n",
            "'#'\n",
            "(Pdb) tokenizer.decode(3)\n",
            "'$'\n",
            "(Pdb) tokenizer.decode(4)\n",
            "'%'\n",
            "(Pdb) tokenizer.decode(400\n",
            "*** SyntaxError: unexpected EOF while parsing\n",
            "(Pdb) tokenizer.decode(400)\n",
            "'th'\n",
            "(Pdb) tokenizer.decode(100)\n",
            "'�'\n",
            "(Pdb) tokenizer.decode(5000)\n",
            "' entirely'\n",
            "(Pdb) tokenizer.decode(50000)\n",
            "' grids'\n",
            "(Pdb) tokenizer.decode(256)\n",
            "' t'\n",
            "(Pdb) tokenizer.decode(255)\n",
            "'�'\n",
            "(Pdb) tokenizer.decode(254\n",
            "*** SyntaxError: unexpected EOF while parsing\n",
            "(Pdb) tokenizer.decode(254)\n",
            "'�'\n",
            "(Pdb) tokenizer.decode(300\n",
            "*** SyntaxError: unexpected EOF while parsing\n",
            "(Pdb) tokenizer.decode(300)\n",
            "' l'\n",
            "(Pdb) tokenizer.decode(400)\n",
            "'th'\n",
            "(Pdb) tokenizer.decode(600)\n",
            "'int'\n",
            "(Pdb) tokenizer.decode(800)\n",
            "' inv'\n",
            "(Pdb) tokenizer.decode(1000)\n",
            "'ale'\n",
            "(Pdb) tokenizer.decode(2000)\n",
            "' mind'\n",
            "(Pdb) tokenizer.decode(3000)\n",
            "' News'\n",
            "(Pdb) tokenizer.decode(4000)\n",
            "' pun'\n",
            "(Pdb) tokenizer.decode(50000)\n",
            "' grids'\n",
            "(Pdb) tokenizer.decode(60000)\n",
            "*** TypeError: 'NoneType' object is not iterable\n",
            "(Pdb) tokenizer.decode(255)\n",
            "'�'\n",
            "(Pdb) ord(tokenizer.decode(255))\n",
            "65533\n",
            "(Pdb) ord('a')\n",
            "97\n",
            "(Pdb) ord(tokenizer.decode(257))\n",
            "*** TypeError: ord() expected a character, but string of length 2 found\n",
            "(Pdb) q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-61ac3f967e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# get the predicted next sub-word (in our case, the word 'man')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpredicted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzpCKzikWxA3",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn2-Iv5RGY_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gpt-2-simple\n",
        "!pip install gtts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUN5YCJsWzAs",
        "colab_type": "code",
        "outputId": "99396b8d-283e-4794-f381-8364992aa60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import string\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import gpt_2_simple as gpt2\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from gtts import gTTS \n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from IPython.display import Audio, HTML\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg7SoAGkGh3Z",
        "colab_type": "code",
        "outputId": "3d69a046-0b9e-4c70-b62c-63b01ab86661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Download the children's book corpus from GitHub\n",
        "!wget -O wiki_simple.txt https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/wiki_simple.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 18:26:35--  https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/wiki_simple.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47667422 (45M) [text/plain]\n",
            "Saving to: ‘wiki_simple.txt’\n",
            "\n",
            "wiki_simple.txt     100%[===================>]  45.46M   199MB/s    in 0.2s    \n",
            "\n",
            "2020-02-20 18:26:36 (199 MB/s) - ‘wiki_simple.txt’ saved [47667422/47667422]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_JZMaHVEOg",
        "colab_type": "text"
      },
      "source": [
        "## Word Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx7LXT0sVLjI",
        "colab_type": "code",
        "outputId": "a3cc4ce2-d573-429d-f9f8-2c50b701e86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Download the simple word distribution from GitHub\n",
        "!wget -O word_dist_full.csv https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/word_dist_full.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 18:26:39--  https://raw.githubusercontent.com/ericburdett/cs673-personal-tutor/master/data/word_dist_full.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 163042 (159K) [text/plain]\n",
            "Saving to: ‘word_dist_full.csv’\n",
            "\n",
            "\rword_dist_full.csv    0%[                    ]       0  --.-KB/s               \rword_dist_full.csv  100%[===================>] 159.22K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-02-20 18:26:39 (5.17 MB/s) - ‘word_dist_full.csv’ saved [163042/163042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWVYaEVrV065",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordDist(Dataset):\n",
        "  def __init__(self):\n",
        "    self.df = pd.read_csv('word_dist_full.csv', header=None, names=['word', 'freq'])\n",
        "  \n",
        "  def getdf(self):\n",
        "    return self.df\n",
        "\n",
        "  def dict_normalized(self): \n",
        "    copy = self.df.copy()\n",
        "    copy['freq'] = copy['freq'] / copy['freq'].max()\n",
        "\n",
        "    return copy.set_index('word').to_dict()['freq']\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.df['word'][index], self.df['freq'][index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9LYBu6EVIkA",
        "colab_type": "text"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuQNroOuIg1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that deals with training and generating text from GPT2\n",
        "class LanguageModel():\n",
        "  def __init__(self, model='124M', genre='children', train_steps=200, max_length=150):\n",
        "    self.download_model(model)\n",
        "    self.genre = genre\n",
        "    self.max_length = max_length\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    self.sess = gpt2.start_tf_sess()\n",
        "\n",
        "    if genre == 'children':\n",
        "      gpt2.finetune(self.sess, 'wiki_simple.txt', model_name=model, steps=train_steps)\n",
        "    else:\n",
        "      raise('The specified genre does not exist')\n",
        "\n",
        "  # Returns a list of sample texts with a given prefix and suffix\n",
        "  def generate_text(self, prefix='<|startoftext|>', suffix='.', include_prefix=False, nsamples=5):\n",
        "    if nsamples < 1 or nsamples > 20:\n",
        "      raise('Error: nsamples must be within the range 1 <= x <= 20')\n",
        "\n",
        "    return gpt2.generate(self.sess, prefix=prefix, truncate=suffix, include_prefix=include_prefix, batch_size=nsamples, nsamples=nsamples, return_as_list=True, length=self.max_length)\n",
        "  \n",
        "  def download_model(self, model_name):\n",
        "    if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "      print(f\"Downloading {model_name} model...\")\n",
        "      gpt2.download_gpt2(model_name=model_name)\n",
        "    else:\n",
        "      print(f\"{model_name} model is already downloaded\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQxMeo2JNzSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A class that contains some knowledge that the user has acquired over time.\n",
        "# For example, it may hold the words that the user knows (and how well the user knows them)\n",
        "class UserKnowledge():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # We will likely need some place to store the knowledge we acquire about the user\n",
        "  # so that we can access it from session to session\n",
        "  def save_knowledge(self, path):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK1wDhdgJajQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that evaluates sentences based on what the system knows about the user\n",
        "class SentenceEvaluator():\n",
        "  def __init__(self, level='beginner', user_knowledge=None):\n",
        "    self.level = 'beginner'\n",
        "    self.word_dist = WordDist().dict_normalized()\n",
        "    self.word_dist_threshold = 0.033\n",
        "    self.word_dist_threshold_step = 0.005\n",
        "    self.word_dist_difficulty_threshold = 7\n",
        "\n",
        "    if user_knowledge == None:\n",
        "      self.user_knowledge = UserKnowledge()\n",
        "    else:\n",
        "      self.user_knowledge = user_knowledge\n",
        "\n",
        "  # We will likely want some method to update the user_knowledge in the evaluator\n",
        "  # Maybe, we will only pass user_knowledge into the evaluate function?...\n",
        "  def update_user_knowledge(user_knowledge):\n",
        "    pass\n",
        "\n",
        "  # Score the sentences and return the sentence with the highest score\n",
        "  def evaluate(self, sentences):\n",
        "    scores = self.score(sentences)\n",
        "    high_score_index = np.argmax(scores)\n",
        "\n",
        "    return sentences[high_score_index]\n",
        "\n",
        "  # Score each sentence based on some criteria\n",
        "  def score(self, sentences):\n",
        "    scores = []\n",
        "    for sentence in sentences:\n",
        "      score = 0\n",
        "      score += self.length_score(sentence)\n",
        "      score += self.word_difficulty(sentence)\n",
        "\n",
        "      # add other criteria for scoring\n",
        "      # ...\n",
        "      # ...\n",
        "      scores.append(score)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "  # For beginners, we want to favor shorter sentences\n",
        "  # This method should change as we increase difficulty level\n",
        "  def length_score(self, sentence):\n",
        "    length = len(sentence)\n",
        "\n",
        "    if self.level == 'beginner':\n",
        "      if length > 0 and length <= 15:\n",
        "        return 6\n",
        "      elif length > 15 and length <= 25:\n",
        "        return 10\n",
        "      elif length > 25 and length <= 35:\n",
        "        return 7\n",
        "      elif length > 35 and length <= 45:\n",
        "        return 3\n",
        "      elif length > 45 and length <= 55:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "    else:\n",
        "      raise('support for non-beginners is not supported')\n",
        "\n",
        "  # For beginners, easier the better!\n",
        "  # This method should change as we increase difficulty level\n",
        "  def word_difficulty(self, sentence):\n",
        "    word_scores = []\n",
        "\n",
        "    for word in sentence.split(' '):\n",
        "      word = word.lower()\n",
        "      word_score = self.word_dist.get(word, 0) # Return the word or 0 if it doesn't exist\n",
        "\n",
        "      if word_score >= self.word_dist_threshold:\n",
        "        word_scores.append(10)\n",
        "      elif word_score >= self.word_dist_threshold - self.word_dist_threshold_step:\n",
        "        word_scores.append(8)\n",
        "      elif word_score >= self.word_dist_threshold - (2 * self.word_dist_threshold_step):\n",
        "        word_scores.append(6)\n",
        "      elif word_score >= self.word_dist_threshold - (3 * self.word_dist_threshold_step):\n",
        "        word_scores.append(4)\n",
        "      elif word_score >= self.word_dist_threshold - (4 * self.word_dist_threshold_step):\n",
        "        word_scores.append(2)\n",
        "      else:\n",
        "        word_scores.append(0)\n",
        "\n",
        "    score_med = np.median(word_scores)\n",
        "\n",
        "    if score_med >= self.word_dist_difficulty_threshold:\n",
        "      return 10\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 1:\n",
        "      return 8\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 2:\n",
        "      return 6\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 3:\n",
        "      return 4\n",
        "    elif score_med >= self.word_dist_difficulty_threshold - 4:\n",
        "      return 2\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVxCTzArHKdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGenerator():\n",
        "  def __init__(self, language_model=None, evaluator=None):\n",
        "    if language_model == None:\n",
        "      self.language_model = LanguageModel()\n",
        "    else:\n",
        "      self.language_model = language_model\n",
        "    if evaluator == None:\n",
        "      self.evaluator = SentenceEvaluator()\n",
        "    else:\n",
        "      self.evaluator = evaluator\n",
        "\n",
        "  # Generate a sentence, pick the best one based on evaluation, return the sentence\n",
        "  def generate(self, print_all_sentences=False):\n",
        "    # Determine the prefix/suffix based on some kind of criteria that is learned over time\n",
        "    prefix = self.determine_prefix()\n",
        "    if prefix == '<|startoftext|>':\n",
        "      include_prefix = False\n",
        "    else:\n",
        "      include_prefix = True\n",
        "    suffix = self.determine_suffix()\n",
        "\n",
        "    sentences = self.language_model.generate_text(prefix=prefix, suffix=suffix, include_prefix=include_prefix, nsamples=15)\n",
        "    sentences = self.filter_punctuation(sentences)\n",
        "    best_sentence = self.evaluator.evaluate(sentences)\n",
        "\n",
        "    if print_all_sentences:\n",
        "      for sentence in sentences:\n",
        "        print(sentence)\n",
        "\n",
        "    return best_sentence\n",
        "  \n",
        "  # Used to filter unwanted punctuation GPT2 might produce, like newlines\n",
        "  def filter_punctuation(self, sentences):\n",
        "    filtered_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "      new_sentence = sentence.replace('\\n', ' ')\n",
        "      new_sentence = new_sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "      filtered_sentences.append(new_sentence)\n",
        "\n",
        "    return filtered_sentences\n",
        "\n",
        "  def determine_prefix(self):\n",
        "    # Good simple sentence starters...\n",
        "    # starters = ['<|startoftext|>']\n",
        "    starters = ['I', 'You', 'The', 'They', 'It', '<|startoftext|>', 'He', 'She', 'My']\n",
        "    random_index = np.random.randint(0, len(starters)) \n",
        "\n",
        "    return starters[random_index]\n",
        "\n",
        "  def determine_suffix(self):\n",
        "    return '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpZvu9GMVu-O",
        "colab_type": "text"
      },
      "source": [
        "## Tutoring System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJB-19P2Rlh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LanguageModel('117M', train_steps=200) # Will fine-tune model everytime this is called! -- Will need to be fixed at some point"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIEVzlnWc9EF",
        "colab_type": "code",
        "outputId": "1baf679a-474a-4a27-9b88-f6119beaa1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "generator = SentenceGenerator(language_model=model)\n",
        "best_sentence = generator.generate(print_all_sentences=True)\n",
        "print(\"Best Sentence: \", best_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My own experience with it was that it was a very funny and funny movie \n",
            "My game is an open world game \n",
            "My second favorite place to eat is at a nearby lake \n",
            "My name is Washington SmootHart  and I am an agent of the United Nations \n",
            "Myrious s talk with the King of France was not well received and the book was banned \n",
            "My wife and her brother were at home when a sudden  thunderbolt  struck the house \n",
            "My money was full of things that are not in the movie and were not intended for audience or to be seen by children \n",
            "My favorite game is High Roller Ballet \n",
            "My own life was spent in the city and in the West Bank  and belonged to the family of the people who lived there \n",
            "My hair is round and it looks like the shaft of a gun \n",
            "My way was to go to a village called Namur in Afghanistan in 1959 \n",
            "My students were supposed to be students at the University of East Anglia  but they were supposed to be studying in the department of English \n",
            "My statutes were changed to go with the Dukes of France  and the Duke of Normandy  who was Grand Duke of Austria \n",
            "My precious mama and I were taken to a hospital in India \n",
            "My clan was part of the Second Temple of Jerusalem \n",
            "Best Sentence:  My hair is round and it looks like the shaft of a gun \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5PrmYHIZL0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_options():\n",
        "  print('0: I don\\'t know what this means.')\n",
        "  print('1: Choose words I don\\'t know.')\n",
        "  print('2: Generate a better sentence.')\n",
        "  print('3: I need definitions.')\n",
        "  print('4: I understand! Give me another!')\n",
        "  print('5: Exit: I\\'ve learned enough for today.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh3HWeS6hLG8",
        "colab_type": "text"
      },
      "source": [
        "## Text-to-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uN47D4-hPTc",
        "colab_type": "code",
        "outputId": "9ee909db-08e4-46d4-a4d3-188ff06f33cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "speech = gTTS(text = best_sentence, lang = 'en', slow = False)\n",
        "speech.save('speech.mp3')\n",
        "Audio(filename='speech.mp3', autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht56XkiOmoEu",
        "colab_type": "code",
        "outputId": "e57854da-f25a-44ff-e45d-e080e1d1f5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Audio('Hedidnotlikethesoundofit.mp3', autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "something\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psl0v8GaeRBq",
        "colab_type": "text"
      },
      "source": [
        "## Learn-A-Language Loop\n",
        "* Terrible Name...\n",
        "* We need to come up with something!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fe02ce7f-500c-46a5-9829-94b0a5a12cb2",
        "id": "PxyjwQtX3Het",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        }
      },
      "source": [
        "print(\"Learn-A-Language - English\")\n",
        "\n",
        "while True:\n",
        "  print('\\nGenerating personalized sentence... Please Wait.')\n",
        "  sentence = generator.generate()\n",
        "  print(\"\\nTry this sentence:\")\n",
        "  print(sentence, '\\n')\n",
        "  speech = gTTS(text=sentence, lang='en', slow=False)\n",
        "  filename = sentence.replace(' ', '') + '.mp3'\n",
        "  speech.save(filename)\n",
        "  \n",
        "\n",
        "  while True:\n",
        "    print_options()\n",
        "    Audio(filename=filename, autoplay=False)\n",
        "    code = input('Enter a code from above:')\n",
        "    if code in ['0','1','2','3','4','5']:\n",
        "      code = int(code)\n",
        "      break\n",
        "    print('')\n",
        "  \n",
        "  if code == 0:\n",
        "    print('\\nI\\'m Sorry! This is as get as it gets...')\n",
        "  elif code == 1:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 2:\n",
        "    print('\\nNew sentence coming right up!')\n",
        "  elif code == 3:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 4:\n",
        "    print('\\nGreat Job! Here\\'s another.')\n",
        "  else:\n",
        "    print('\\nThanks for using Learn-A-Language! Play again soon!')\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn-A-Language - English\n",
            "\n",
            "Generating personalized sentence... Please Wait.\n",
            "\n",
            "Try this sentence:\n",
            "He did not like the sound of it  \n",
            "\n",
            "0: I don't know what this means.\n",
            "1: Choose words I don't know.\n",
            "2: Generate a better sentence.\n",
            "3: I need definitions.\n",
            "4: I understand! Give me another!\n",
            "5: Exit: I've learned enough for today.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6421a3d1a441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter a code from above:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT9XoYSjXnQ1",
        "colab_type": "code",
        "outputId": "fe02ce7f-500c-46a5-9829-94b0a5a12cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        }
      },
      "source": [
        "print(\"Learn-A-Language - English\")\n",
        "\n",
        "while True:\n",
        "  print('\\nGenerating personalized sentence... Please Wait.')\n",
        "  sentence = generator.generate()\n",
        "  print(\"\\nTry this sentence:\")\n",
        "  print(sentence, '\\n')\n",
        "  speech = gTTS(text=sentence, lang='en', slow=False)\n",
        "  filename = sentence.replace(' ', '') + '.mp3'\n",
        "  speech.save(filename)\n",
        "  Audio(filename=filename, autoplay=False)\n",
        "\n",
        "  while True:\n",
        "    print_options()\n",
        "    Audio(filename=filename, autoplay=False)\n",
        "    code = input('Enter a code from above:')\n",
        "    if code in ['0','1','2','3','4','5']:\n",
        "      code = int(code)\n",
        "      break\n",
        "    print('')\n",
        "  \n",
        "  if code == 0:\n",
        "    print('\\nI\\'m Sorry! This is as good as it gets...')\n",
        "  elif code == 1:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 2:\n",
        "    print('\\nNew sentence coming right up!')\n",
        "  elif code == 3:\n",
        "    print('\\nI\\'m Sorry! This functionality isn\\'t currently available.')\n",
        "  elif code == 4:\n",
        "    print('\\nGreat Job! Here\\'s another.')\n",
        "  else:\n",
        "    print('\\nThanks for using Learn-A-Language! Play again soon!')\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn-A-Language - English\n",
            "\n",
            "Generating personalized sentence... Please Wait.\n",
            "\n",
            "Try this sentence:\n",
            "He did not like the sound of it  \n",
            "\n",
            "0: I don't know what this means.\n",
            "1: Choose words I don't know.\n",
            "2: Generate a better sentence.\n",
            "3: I need definitions.\n",
            "4: I understand! Give me another!\n",
            "5: Exit: I've learned enough for today.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6421a3d1a441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter a code from above:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}